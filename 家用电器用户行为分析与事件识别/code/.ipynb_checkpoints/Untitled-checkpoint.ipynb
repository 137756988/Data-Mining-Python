{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验介绍\n",
    "## 实验背景\n",
    "根据用户的用水行为，识别出用户的洗浴行为。厂商可对热水器进行优化改进。对不同客户群提供个性化产品、改进产品智能化和制定相应营销策略。\n",
    "本实验的精彩之处在于如何对原始数据进行时间序列化处理，来构造模型数据。\n",
    "\n",
    "## 实验目标\n",
    "\n",
    "1） 根据热水器采集到的数据，划分一次完整用水事件。\n",
    "2） 在划分好的一次完整的用水事件中，识别出洗浴事件。\n",
    "\n",
    "在本次实验中，我们使用到的原始数据集如下图：\n",
    "（插图）\n",
    "我们将根据水流量和停顿时间间隔划分为不同大小的时间区间，每个区间是一次可理解的一次完整用水事件。并从其中识别出属于洗浴的事件。\n",
    "\n",
    "## 实验步骤\n",
    "\n",
    "实验步骤如下：\n",
    "（插图）\n",
    "1） 对热水用户的历史用水数据进行选择性抽取，构建专家样本。 \n",
    "2） 对步骤1形成的数据集进行数据探索与预处理。包括探索用水时间时间间隔的分布，规约冗余属性、识别用水数据的缺失值，并对缺失值进行处理，根据建模的需要进行属性构造等。 \n",
    "3） 在步骤2的建模样数据基础上，建立洗浴事件识别模型，对洗浴事件识别模型进行分析评价。 \n",
    "4） 对步骤3形成的模型结果应用并对洗浴事件划分进行优化。 \n",
    "5） 调用洗浴时间识别模型，对实时监控的热水器流水数据进行洗浴时间自动识别。\n",
    "\n",
    "# 数据处理\n",
    "## 数据抽取\n",
    "\n",
    "由于数据量比较大，对原始数据采用无放回随机抽样200家用户2014.1.1——2014.12.31的用水记录建模。抽取后的数据总共包括12个属性：热水器编码、发生时间、开关状态、加热中、保温中、有无水流、实际温度、热水量、水流量、节能模式、加热剩余时间、当前设置温度。\n",
    "\n",
    "## 数据探索分析\n",
    "\n",
    "对于抽取后的数据，我们需要对两次水流量不为0的用水记录的时间间隔进行统计分析。用水停顿时间间隔定义为一条水流量不为0的流水记录同下一条水流量不为0的流水记录之间的时间间隔。通过分析用户用水停顿时间间隔的规律性，从而设定划分一次完整用水事件的时间间隔阈值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filepath = '../data/original_data.xls'\n",
    "\n",
    "data = pd.read_excel(filepath,encoding='utf-8')\n",
    "\n",
    "data[u'发生时间'] = pd.to_datetime(data[u'发生时间'],format='%Y%m%d%H%M%S')\n",
    "data = data[data[u'水流量'] > 0]\n",
    "#d = data[u'发生时间'].diff()\n",
    "timediff = (data[u'发生时间'].diff().dt.seconds/60).astype(float)\n",
    "\n",
    "d = pd.DataFrame(timediff)\n",
    "\n",
    "d.loc[((d[u\"发生时间\"]>0)&(d[u\"发生时间\"]<0.1)),'0-0.1']=1\n",
    "d.loc[((d[u\"发生时间\"]>=0.1)&(d[u\"发生时间\"]<0.2)),'0.1-0.2']=1\n",
    "d.loc[((d[u\"发生时间\"]>=0.2)&(d[u\"发生时间\"]<0.3)),'0.2-0.3']=1\n",
    "d.loc[((d[u\"发生时间\"]>=0.3)&(d[u\"发生时间\"]<0.5)),'0.3-0.5']=1\n",
    "d.loc[((d[u\"发生时间\"]>=0.5)&(d[u\"发生时间\"]<1)),'0.5-1']=1\n",
    "d.loc[((d[u\"发生时间\"]>=1)&(d[u\"发生时间\"]<2)),'1-2']=1\n",
    "d.loc[((d[u\"发生时间\"]>=2)&(d[u\"发生时间\"]<3)),'2-3']=1\n",
    "d.loc[((d[u\"发生时间\"]>=3)&(d[u\"发生时间\"]<4)),'3-4']=1\n",
    "d.loc[((d[u\"发生时间\"]>=4)&(d[u\"发生时间\"]<5)),'4-5']=1\n",
    "d.loc[((d[u\"发生时间\"]>=5)&(d[u\"发生时间\"]<6)),'5-6']=1\n",
    "d.loc[((d[u\"发生时间\"]>=6)&(d[u\"发生时间\"]<7)),'6-7']=1\n",
    "d.loc[((d[u\"发生时间\"]>=7)&(d[u\"发生时间\"]<8)),'7-8']=1\n",
    "d.loc[((d[u\"发生时间\"]>=8)&(d[u\"发生时间\"]<9)),'8-9']=1\n",
    "d.loc[((d[u\"发生时间\"]>=9)&(d[u\"发生时间\"]<10)),'9-10']=1\n",
    "d.loc[((d[u\"发生时间\"]>=10)&(d[u\"发生时间\"]<11)),'10-11']=1\n",
    "d.loc[((d[u\"发生时间\"]>=11)&(d[u\"发生时间\"]<12)),'11-12']=1\n",
    "d.loc[((d[u\"发生时间\"]>=12)&(d[u\"发生时间\"]<13)),'12-13']=1\n",
    "d.loc[(d[u\"发生时间\"]>=13),'13']=1\n",
    "\n",
    "\n",
    "\n",
    "d = pd.DataFrame(d.sum()).T\n",
    "d.iloc[:,1:].apply(lambda x:x/data.shape[0]*100)\n",
    "#hist绘制直方图，对每一列显示单独一个直方图\n",
    "\n",
    "d.to_excel('../tmp/frequency_count.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过对数据的操作，我们可以看出停顿时间间隔在0-0.3分钟的频率很高，结合日常经验可以判断该间隔应归为一次用水时间中的停顿；停顿时间间隔为6-13分钟的频率较低，分析其为两次用水事件之间的停顿间隔。两次用水事件的停顿时间间隔分布在3-7分钟。\n",
    "\n",
    "## 数据预处理\n",
    "\n",
    "观察我们的数据可知，依旧存在数据的普遍问题，缺失值处理，与实验目标无关的属性等。本实验我们针对这些情况相应地应用了缺失值处理、数据规约和属性构造等方法。\n",
    "\n",
    "### 数据规约\n",
    "\n",
    "属性规约：将与判定用户洗浴行为无关的属性去除。剩余9个属性:发生时间、开关状态、加热中、保温中、实际温度、热水量、水流量、加热剩余时间、当前设置温度 \n",
    "数值规约：数据中，“开关机状态”为“关”，且水流量为0时，此时热水器不处于工作状态，数据记录可以丢弃。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(filepath,encoding='utf-8')\n",
    "\n",
    "data[u'发生时间'] = pd.to_datetime(data[u'发生时间'],format='%Y%m%d%H%M%S')\n",
    "\n",
    "index1 = data[u'开关机状态'] != '关'\n",
    "index2 = data[u'水流量'].astype(int) != 0\n",
    "reduct_data = data[index1 | index2].copy()\n",
    "reduct_data = reduct_data[[u'发生时间',u'开关机状态',u'加热中',u'保温中',u'实际温度',u'热水量',u'水流量',u'加热剩余时间',u'当前设置温度']]\n",
    "\n",
    "\n",
    "reduct_data.to_excel('../tmp/water_data.xls',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据变换\n",
    "\n",
    "由于本实验的挖掘目标是对用户行为中的洗浴事件进行识别，这就需要从用户的各种用水事件（洗漱，洗菜，刷碗和洗澡等）中识别出洗浴事件。首先则是要先识别出一次完整的用水事件。\n",
    "一次完整的用水事件是根据水流量和停顿时间间隔的阈值来划分的。根据上节对用户用水时间间隔的规律分析，将阈值暂定为4。\n",
    "\n",
    "1）划分一次完整的用水事件\n",
    "水流量不为0，表示用户正在用水；水流量为0，表示用户用水停顿或者停止用水。\n",
    "如果水流量为0的状态超过阈值T，则从该段水流量为0的状态向前寻找最后一条水流量不为0的用水记录作为上次用水事件的结束；向后寻找水流量不为0的用水记录作为下次用水事件的开始。\n",
    "\n",
    "划分步骤： \n",
    "1 读取数据，识别第一条用水记录不为0的数据记录为R1，按顺序识别下一条水流量不为0的记录为R2； \n",
    "2 若gap_i > T，则R_i+1与R_i之间的记录不能划分到同一次用水事件中，将R_i+1作为新的读取数据记录的开始； 若gap_i < T，则R_i+1与R_i之间的记录划分到同一次用水事件中，并将接下来水流量不为0的数据记录为R_i+2 \n",
    "3 循环执行步骤2，直到数据读取完毕，结束事件划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n"
     ]
    }
   ],
   "source": [
    "threshold = pd.Timedelta(minutes = 4)\n",
    "data = pd.read_excel('../tmp/water_data.xls',encoding = 'utf-8')\n",
    "data[u'发生时间'] = pd.to_datetime(data[u'发生时间'],format='%Y%m%d%H%M%S')\n",
    "data = data[data[u'水流量'] > 0]\n",
    "\n",
    "d = data[u'发生时间'].diff() > threshold\n",
    "data[u'事件编号'] = d.cumsum() + 1\n",
    "\n",
    "data.to_excel('../tmp/divideAction.xls',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)用水事件阈值寻优模型\n",
    "\n",
    "在上一节中，我们将时间间隔的阈值设为4。但这只是我们对数据简单统计分析后得到的结果。本节就阈值来更新寻找最优的阈值。\n",
    "由于地域问题，人们对热水器的使用习惯不同；根据季节变化和时间的不同，对热水器的使用也有相应的变化。\n",
    "\n",
    "使用不同的阈值，会得到不同的划分事件结果数：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "def findsum(threshold):\n",
    "    d = data[u'发生时间'].diff() > threshold\n",
    "    #data[u'事件编号'] = d.cumsum() + 1\n",
    "    #return data[u'事件编号'].tolist()[-1]\n",
    "    return d.sum() + 1\n",
    "\n",
    "dt = [pd.Timedelta(minutes = i/100) for i in range(100,900,25)]\n",
    "h = pd.DataFrame(dt,columns = [u'阈值'])\n",
    "h[u'事件数'] = h[u'阈值'].apply(findsum)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#显示中文\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "plt.plot(np.arange(1,9,0.25), h[u'事件数'])\n",
    "plt.xlabel(u'阈值')\n",
    "plt.ylabel(u'事件数')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从阈值与事件数的关系图可以看出，在某段阈值范围内，下降趋势明显，说明在该段阈值范围内，用户的停顿习惯比较集中。在阈值4-5之间，曲线的斜率趋于稳定，说明这段时间内用户的停顿习惯趋于稳定。所以取平缓的时间段中的开始时间作为阈值，既不会将短的用水事件合并，又不会将长的用水事件拆开。\n",
    "\n",
    "接下来，我们使用python对用户的用水数据划分阈值进行寻优。寻优区间在1分钟-9分钟。\n",
    "在寻优过程中，以曲线的斜率为指标。即寻找所有阈值中斜率指标最小的阈值。此处使用一个专家阈值5。如果该阈值的斜率指标小于5，则取该阈值作为用水事件划分的阈值；如果该阈值的斜率指标不小于5，则阈值取默认值4分钟。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 days 00:04:00\n"
     ]
    }
   ],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "inpath = '../tmp/water_data.xls'\n",
    "\n",
    "n = 4 #此处使用每个点后的4个点来计算该点的斜率指标\n",
    "\n",
    "threshold = pd.Timedelta(minutes = 5) #专家阈值\n",
    "\n",
    "data = pd.read_excel(inpath,encoding='utf-8')\n",
    "data[u'发生时间'] = pd.to_datetime(data[u'发生时间'],format='%Y%m%d%H%M%S')\n",
    "data = data[data[u'水流量'] > 0]\n",
    "\n",
    "def event_sum(ts):\n",
    "    d = data[u'发生时间'].diff() > ts\n",
    "    return d.sum() + 1\n",
    "\n",
    "dt = [pd.Timedelta(minutes = i) for i in np.arange(1,9,0.25)]\n",
    "h = pd.DataFrame(dt,columns = [u'阈值'])\n",
    "h[u'事件数'] = h[u'阈值'].apply(event_sum)\n",
    "h[u'斜率'] = h[u'事件数'].diff()/0.25 #计算每两个相邻点对应的斜率\n",
    "#h[u'斜率指标'] = pd.rolling_mean(h[u'斜率'].abs(),n) #使用后n个的斜率绝对值平均作为斜率指标\n",
    "h[u'斜率指标'] = h[u'斜率'].abs().rolling(n).mean()\n",
    "\n",
    "ts = h[u'阈值'][h[u'斜率指标'].idxmin() - n]\n",
    "#idxmin返回最小值的Index,由于rolling_mean()自动计算前n个斜率的绝对值平均值，所以结果要平移（-n）\n",
    "\n",
    "if ts > threshold:\n",
    "    ts = pd.Timedelta(minutes = 4)\n",
    "    \n",
    "print(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据我们的寻优代码，得到该段时间用水事件划分的最优阈值为4分钟。\n",
    "3）属性构造\n",
    "根据我们的研究目标，设定4类指标：时长指标、频率指标、用水量化指标、用水波动指标。\n",
    "（插图）\n",
    "4）筛选出“候选洗浴事件”\n",
    "\n",
    "从已经划分好的用水事件中识别出洗浴事件 \n",
    "首先用3个比较宽松的条件筛选掉那些非常短暂的用水事件，这3个条件是“或”的关系。\n",
    "    1.一次用水事件的总用水量（纯热水）小于y升 \n",
    "    2.用水时长小于100秒（用水时间，不包括停顿） \n",
    "    3.总用水时长小于120秒（事件开始到结束） \n",
    "    \n",
    "（插图）\n",
    "对于Y的取值，此处我们基于热量守恒建立了标准热水量换算模型的计算公式。\n",
    "根据公式来计算用水事件在不同实际用水温度下的标准热水使用量。\n",
    "\n",
    "### 数据清洗\n",
    "\n",
    "在用水状态记录缺失的的情况下，填充一条状态记录使水流量为0，发生时间加2秒，其余属性状态不变。\n",
    "\n",
    "\n",
    "## 模型建立\n",
    "在本实验中，由于数据并未给出数据标签。无法对模型进行训练。\n",
    "此处我们使用一部分已经标注好的数据来对模型进行训练\n",
    "（插图）\n",
    "\n",
    "根据用户提供的用水日志，将其中洗浴事件的数据状态记录作为训练样本训练多层神经网络。\n",
    "使用“候选洗浴事件”的11个属性作为网络的输入，训练BP网络时给定的输出是1与0。1代表是洗浴事件，0则不是。这个判断是用户提供的。\n",
    "\n",
    "训练神经网络时，对神经网络的参数进行了寻优。\n",
    "发现含二个隐层的神经网络训练效果较好，其中二个隐层的隐节点数分别为17、10时训练的效果较好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " - 1s - loss: 11.5761 - acc: 0.2143\n",
      "Epoch 2/500\n",
      " - 0s - loss: 12.6517 - acc: 0.2143\n",
      "Epoch 3/500\n",
      " - 0s - loss: 10.0179 - acc: 0.3571\n",
      "Epoch 4/500\n",
      " - 0s - loss: 12.6470 - acc: 0.2143\n",
      "Epoch 5/500\n",
      " - 0s - loss: 11.4780 - acc: 0.2500\n",
      "Epoch 6/500\n",
      " - 0s - loss: 10.8206 - acc: 0.3214\n",
      "Epoch 7/500\n",
      " - 0s - loss: 10.9677 - acc: 0.2857\n",
      "Epoch 8/500\n",
      " - 0s - loss: 7.5402 - acc: 0.5000\n",
      "Epoch 9/500\n",
      " - 0s - loss: 9.1730 - acc: 0.4286\n",
      "Epoch 10/500\n",
      " - 0s - loss: 10.3566 - acc: 0.3571\n",
      "Epoch 11/500\n",
      " - 0s - loss: 9.7734 - acc: 0.3929\n",
      "Epoch 12/500\n",
      " - 0s - loss: 10.3032 - acc: 0.3571\n",
      "Epoch 13/500\n",
      " - 0s - loss: 10.7067 - acc: 0.2857\n",
      "Epoch 14/500\n",
      " - 0s - loss: 10.3554 - acc: 0.3571\n",
      "Epoch 15/500\n",
      " - 0s - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 16/500\n",
      " - 0s - loss: 9.7860 - acc: 0.3929\n",
      "Epoch 17/500\n",
      " - 0s - loss: 11.0426 - acc: 0.2857\n",
      "Epoch 18/500\n",
      " - 0s - loss: 10.0608 - acc: 0.3571\n",
      "Epoch 19/500\n",
      " - 0s - loss: 9.2041 - acc: 0.4286\n",
      "Epoch 20/500\n",
      " - 0s - loss: 10.7114 - acc: 0.3214\n",
      "Epoch 21/500\n",
      " - 0s - loss: 10.8160 - acc: 0.2857\n",
      "Epoch 22/500\n",
      " - 0s - loss: 9.9634 - acc: 0.3571\n",
      "Epoch 23/500\n",
      " - 0s - loss: 9.7672 - acc: 0.3929\n",
      "Epoch 24/500\n",
      " - 0s - loss: 10.5959 - acc: 0.3214\n",
      "Epoch 25/500\n",
      " - 0s - loss: 9.6219 - acc: 0.3571\n",
      "Epoch 26/500\n",
      " - 0s - loss: 10.4488 - acc: 0.3214\n",
      "Epoch 27/500\n",
      " - 0s - loss: 10.2381 - acc: 0.3571\n",
      "Epoch 28/500\n",
      " - 0s - loss: 7.9407 - acc: 0.4286\n",
      "Epoch 29/500\n",
      " - 0s - loss: 10.1185 - acc: 0.3571\n",
      "Epoch 30/500\n",
      " - 0s - loss: 6.1867 - acc: 0.5714\n",
      "Epoch 31/500\n",
      " - 0s - loss: 6.3109 - acc: 0.6071\n",
      "Epoch 32/500\n",
      " - 0s - loss: 5.6110 - acc: 0.6429\n",
      "Epoch 33/500\n",
      " - 0s - loss: 6.5165 - acc: 0.5714\n",
      "Epoch 34/500\n",
      " - 0s - loss: 9.6185 - acc: 0.3929\n",
      "Epoch 35/500\n",
      " - 0s - loss: 7.2722 - acc: 0.4643\n",
      "Epoch 36/500\n",
      " - 0s - loss: 5.8388 - acc: 0.6071\n",
      "Epoch 37/500\n",
      " - 0s - loss: 6.2913 - acc: 0.6071\n",
      "Epoch 38/500\n",
      " - 0s - loss: 6.4434 - acc: 0.5714\n",
      "Epoch 39/500\n",
      " - 0s - loss: 4.1710 - acc: 0.7143\n",
      "Epoch 40/500\n",
      " - 0s - loss: 3.7360 - acc: 0.7143\n",
      "Epoch 41/500\n",
      " - 0s - loss: 2.6204 - acc: 0.8214\n",
      "Epoch 42/500\n",
      " - 0s - loss: 3.9013 - acc: 0.7500\n",
      "Epoch 43/500\n",
      " - 0s - loss: 3.9006 - acc: 0.7500\n",
      "Epoch 44/500\n",
      " - 0s - loss: 5.4093 - acc: 0.6429\n",
      "Epoch 45/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 46/500\n",
      " - 0s - loss: 3.9989 - acc: 0.7500\n",
      "Epoch 47/500\n",
      " - 0s - loss: 5.4076 - acc: 0.6429\n",
      "Epoch 48/500\n",
      " - 0s - loss: 3.5384 - acc: 0.7500\n",
      "Epoch 49/500\n",
      " - 0s - loss: 3.5386 - acc: 0.7500\n",
      "Epoch 50/500\n",
      " - 0s - loss: 5.1432 - acc: 0.6786\n",
      "Epoch 51/500\n",
      " - 0s - loss: 3.7408 - acc: 0.7143\n",
      "Epoch 52/500\n",
      " - 0s - loss: 5.4608 - acc: 0.6429\n",
      "Epoch 53/500\n",
      " - 0s - loss: 4.0044 - acc: 0.7500\n",
      "Epoch 54/500\n",
      " - 0s - loss: 4.7073 - acc: 0.6429\n",
      "Epoch 55/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 56/500\n",
      " - 0s - loss: 3.4225 - acc: 0.7857\n",
      "Epoch 57/500\n",
      " - 0s - loss: 4.0166 - acc: 0.7500\n",
      "Epoch 58/500\n",
      " - 0s - loss: 2.8653 - acc: 0.8214\n",
      "Epoch 59/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 60/500\n",
      " - 0s - loss: 3.6936 - acc: 0.7500\n",
      "Epoch 61/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 62/500\n",
      " - 0s - loss: 5.1432 - acc: 0.6786\n",
      "Epoch 63/500\n",
      " - 0s - loss: 2.9179 - acc: 0.7857\n",
      "Epoch 64/500\n",
      " - 0s - loss: 6.2697 - acc: 0.6071\n",
      "Epoch 65/500\n",
      " - 0s - loss: 2.3629 - acc: 0.7857\n",
      "Epoch 66/500\n",
      " - 0s - loss: 3.7342 - acc: 0.7500\n",
      "Epoch 67/500\n",
      " - 0s - loss: 2.2775 - acc: 0.8571\n",
      "Epoch 68/500\n",
      " - 0s - loss: 2.8548 - acc: 0.8214\n",
      "Epoch 69/500\n",
      " - 0s - loss: 4.5738 - acc: 0.7143\n",
      "Epoch 70/500\n",
      " - 0s - loss: 3.8502 - acc: 0.7500\n",
      "Epoch 71/500\n",
      " - 0s - loss: 2.8737 - acc: 0.7857\n",
      "Epoch 72/500\n",
      " - 0s - loss: 3.4225 - acc: 0.7857\n",
      "Epoch 73/500\n",
      " - 0s - loss: 3.4163 - acc: 0.7857\n",
      "Epoch 74/500\n",
      " - 0s - loss: 5.7068 - acc: 0.6429\n",
      "Epoch 75/500\n",
      " - 0s - loss: 4.1225 - acc: 0.7143\n",
      "Epoch 76/500\n",
      " - 0s - loss: 2.9219 - acc: 0.7857\n",
      "Epoch 77/500\n",
      " - 0s - loss: 3.7345 - acc: 0.7500\n",
      "Epoch 78/500\n",
      " - 0s - loss: 4.5675 - acc: 0.7143\n",
      "Epoch 79/500\n",
      " - 0s - loss: 3.3542 - acc: 0.7500\n",
      "Epoch 80/500\n",
      " - 0s - loss: 3.4228 - acc: 0.7857\n",
      "Epoch 81/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 82/500\n",
      " - 0s - loss: 2.8739 - acc: 0.7857\n",
      "Epoch 83/500\n",
      " - 0s - loss: 3.4163 - acc: 0.7857\n",
      "Epoch 84/500\n",
      " - 0s - loss: 4.1486 - acc: 0.7143\n",
      "Epoch 85/500\n",
      " - 0s - loss: 4.2769 - acc: 0.7143\n",
      "Epoch 86/500\n",
      " - 0s - loss: 3.4233 - acc: 0.7857\n",
      "Epoch 87/500\n",
      " - 0s - loss: 3.1751 - acc: 0.7857\n",
      "Epoch 88/500\n",
      " - 0s - loss: 3.0398 - acc: 0.7857\n",
      "Epoch 89/500\n",
      " - 0s - loss: 2.9229 - acc: 0.7857\n",
      "Epoch 90/500\n",
      " - 0s - loss: 5.0832 - acc: 0.6429\n",
      "Epoch 91/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 92/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 93/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 94/500\n",
      " - 0s - loss: 3.4384 - acc: 0.7857\n",
      "Epoch 95/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 96/500\n",
      " - 0s - loss: 3.1034 - acc: 0.7857\n",
      "Epoch 97/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 98/500\n",
      " - 0s - loss: 3.4163 - acc: 0.7857\n",
      "Epoch 99/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 100/500\n",
      " - 0s - loss: 4.0141 - acc: 0.7500\n",
      "Epoch 101/500\n",
      " - 0s - loss: 3.0383 - acc: 0.7857\n",
      "Epoch 102/500\n",
      " - 0s - loss: 3.1802 - acc: 0.7857\n",
      "Epoch 103/500\n",
      " - 0s - loss: 3.8447 - acc: 0.7500\n",
      "Epoch 104/500\n",
      " - 0s - loss: 3.4734 - acc: 0.7500\n",
      "Epoch 105/500\n",
      " - 0s - loss: 2.2775 - acc: 0.8571\n",
      "Epoch 106/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 107/500\n",
      " - 0s - loss: 3.5259 - acc: 0.7500\n",
      "Epoch 108/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 109/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 110/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 111/500\n",
      " - 0s - loss: 2.8691 - acc: 0.8214\n",
      "Epoch 112/500\n",
      " - 0s - loss: 3.6307 - acc: 0.7500\n",
      "Epoch 113/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 114/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 115/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 116/500\n",
      " - 0s - loss: 3.4188 - acc: 0.7857\n",
      "Epoch 117/500\n",
      " - 0s - loss: 4.0055 - acc: 0.7500\n",
      "Epoch 118/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 119/500\n",
      " - 0s - loss: 3.4383 - acc: 0.7857\n",
      "Epoch 120/500\n",
      " - 0s - loss: 3.4771 - acc: 0.7500\n",
      "Epoch 121/500\n",
      " - 0s - loss: 3.3667 - acc: 0.7857\n",
      "Epoch 122/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 123/500\n",
      " - 0s - loss: 3.4383 - acc: 0.7857\n",
      "Epoch 124/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 125/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 126/500\n",
      " - 0s - loss: 3.0723 - acc: 0.7857\n",
      "Epoch 127/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 128/500\n",
      " - 0s - loss: 2.8745 - acc: 0.7857\n",
      "Epoch 129/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 130/500\n",
      " - 0s - loss: 3.6864 - acc: 0.7500\n",
      "Epoch 131/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 132/500\n",
      " - 0s - loss: 3.9142 - acc: 0.7500\n",
      "Epoch 133/500\n",
      " - 0s - loss: 3.9906 - acc: 0.7500\n",
      "Epoch 134/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 135/500\n",
      " - 0s - loss: 3.5752 - acc: 0.7143\n",
      "Epoch 136/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 137/500\n",
      " - 0s - loss: 3.8429 - acc: 0.7500\n",
      "Epoch 138/500\n",
      " - 0s - loss: 4.5675 - acc: 0.7143\n",
      "Epoch 139/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 140/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 141/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 142/500\n",
      " - 0s - loss: 2.8482 - acc: 0.8214\n",
      "Epoch 143/500\n",
      " - 0s - loss: 3.4379 - acc: 0.7857\n",
      "Epoch 144/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 145/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 146/500\n",
      " - 0s - loss: 3.4378 - acc: 0.7857\n",
      "Epoch 147/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 148/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 149/500\n",
      " - 0s - loss: 3.4378 - acc: 0.7857\n",
      "Epoch 150/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 151/500\n",
      " - 0s - loss: 2.8752 - acc: 0.7857\n",
      "Epoch 152/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 153/500\n",
      " - 0s - loss: 3.4378 - acc: 0.7857\n",
      "Epoch 154/500\n",
      " - 0s - loss: 3.4377 - acc: 0.7857\n",
      "Epoch 155/500\n",
      " - 0s - loss: 2.2775 - acc: 0.8571\n",
      "Epoch 156/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 157/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 158/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 159/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 160/500\n",
      " - 0s - loss: 2.8825 - acc: 0.7857\n",
      "Epoch 161/500\n",
      " - 0s - loss: 2.8752 - acc: 0.7857\n",
      "Epoch 162/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 163/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 164/500\n",
      " - 0s - loss: 2.8523 - acc: 0.8214\n",
      "Epoch 165/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 166/500\n",
      " - 0s - loss: 2.8471 - acc: 0.8214\n",
      "Epoch 167/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 168/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 169/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 170/500\n",
      " - 0s - loss: 3.4378 - acc: 0.7857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 172/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 173/500\n",
      " - 0s - loss: 3.8224 - acc: 0.7500\n",
      "Epoch 174/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 175/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 176/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 177/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 178/500\n",
      " - 0s - loss: 2.6054 - acc: 0.8214\n",
      "Epoch 179/500\n",
      " - 0s - loss: 3.0857 - acc: 0.7857\n",
      "Epoch 180/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 181/500\n",
      " - 0s - loss: 3.7238 - acc: 0.7500\n",
      "Epoch 182/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 183/500\n",
      " - 0s - loss: 2.8511 - acc: 0.8214\n",
      "Epoch 184/500\n",
      " - 0s - loss: 3.4376 - acc: 0.7857\n",
      "Epoch 185/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 186/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 187/500\n",
      " - 0s - loss: 3.0988 - acc: 0.7857\n",
      "Epoch 188/500\n",
      " - 0s - loss: 3.8687 - acc: 0.7500\n",
      "Epoch 189/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 190/500\n",
      " - 0s - loss: 3.2040 - acc: 0.7857\n",
      "Epoch 191/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 192/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 193/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 194/500\n",
      " - 0s - loss: 3.4377 - acc: 0.7857\n",
      "Epoch 195/500\n",
      " - 0s - loss: 3.4376 - acc: 0.7857\n",
      "Epoch 196/500\n",
      " - 0s - loss: 2.4935 - acc: 0.8214\n",
      "Epoch 197/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 198/500\n",
      " - 0s - loss: 3.4225 - acc: 0.7857\n",
      "Epoch 199/500\n",
      " - 0s - loss: 3.8004 - acc: 0.7500\n",
      "Epoch 200/500\n",
      " - 0s - loss: 3.4973 - acc: 0.7500\n",
      "Epoch 201/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 202/500\n",
      " - 0s - loss: 2.4581 - acc: 0.8214\n",
      "Epoch 203/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 204/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 205/500\n",
      " - 0s - loss: 3.0077 - acc: 0.7857\n",
      "Epoch 206/500\n",
      " - 0s - loss: 3.4404 - acc: 0.7857\n",
      "Epoch 207/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 208/500\n",
      " - 0s - loss: 3.7903 - acc: 0.7500\n",
      "Epoch 209/500\n",
      " - 0s - loss: 3.5006 - acc: 0.7500\n",
      "Epoch 210/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 211/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 212/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 213/500\n",
      " - 0s - loss: 2.9347 - acc: 0.7857\n",
      "Epoch 214/500\n",
      " - 0s - loss: 3.4163 - acc: 0.7857\n",
      "Epoch 215/500\n",
      " - 0s - loss: 3.4553 - acc: 0.7500\n",
      "Epoch 216/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 217/500\n",
      " - 0s - loss: 3.4225 - acc: 0.7857\n",
      "Epoch 218/500\n",
      " - 0s - loss: 2.5784 - acc: 0.7857\n",
      "Epoch 219/500\n",
      " - 0s - loss: 3.3348 - acc: 0.7857\n",
      "Epoch 220/500\n",
      " - 0s - loss: 2.8470 - acc: 0.8214\n",
      "Epoch 221/500\n",
      " - 0s - loss: 3.4735 - acc: 0.7500\n",
      "Epoch 222/500\n",
      " - 0s - loss: 3.6707 - acc: 0.7500\n",
      "Epoch 223/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 224/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 225/500\n",
      " - 0s - loss: 3.8170 - acc: 0.7500\n",
      "Epoch 226/500\n",
      " - 0s - loss: 3.7392 - acc: 0.7500\n",
      "Epoch 227/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 228/500\n",
      " - 0s - loss: 2.9170 - acc: 0.7857\n",
      "Epoch 229/500\n",
      " - 0s - loss: 3.0366 - acc: 0.7857\n",
      "Epoch 230/500\n",
      " - 0s - loss: 3.4193 - acc: 0.7857\n",
      "Epoch 231/500\n",
      " - 0s - loss: 3.5627 - acc: 0.7500\n",
      "Epoch 232/500\n",
      " - 0s - loss: 3.4585 - acc: 0.7857\n",
      "Epoch 233/500\n",
      " - 0s - loss: 3.4476 - acc: 0.7857\n",
      "Epoch 234/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 235/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 236/500\n",
      " - 0s - loss: 4.0128 - acc: 0.7500\n",
      "Epoch 237/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 238/500\n",
      " - 0s - loss: 3.8871 - acc: 0.7500\n",
      "Epoch 239/500\n",
      " - 0s - loss: 2.8500 - acc: 0.8214\n",
      "Epoch 240/500\n",
      " - 0s - loss: 2.8762 - acc: 0.7857\n",
      "Epoch 241/500\n",
      " - 0s - loss: 3.1333 - acc: 0.7857\n",
      "Epoch 242/500\n",
      " - 0s - loss: 3.3383 - acc: 0.7857\n",
      "Epoch 243/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 244/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 245/500\n",
      " - 0s - loss: 3.1917 - acc: 0.7857\n",
      "Epoch 246/500\n",
      " - 0s - loss: 2.8476 - acc: 0.8214\n",
      "Epoch 247/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 248/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 249/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 250/500\n",
      " - 0s - loss: 3.1452 - acc: 0.7857\n",
      "Epoch 251/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 252/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 253/500\n",
      " - 0s - loss: 2.8756 - acc: 0.7857\n",
      "Epoch 254/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 255/500\n",
      " - 0s - loss: 3.4163 - acc: 0.7857\n",
      "Epoch 256/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 257/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 258/500\n",
      " - 0s - loss: 3.0659 - acc: 0.7857\n",
      "Epoch 259/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 260/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 261/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 262/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 263/500\n",
      " - 0s - loss: 3.4510 - acc: 0.7500\n",
      "Epoch 264/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 265/500\n",
      " - 0s - loss: 3.4376 - acc: 0.7857\n",
      "Epoch 266/500\n",
      " - 0s - loss: 3.4540 - acc: 0.7500\n",
      "Epoch 267/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 268/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 269/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 270/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 271/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 272/500\n",
      " - 0s - loss: 3.3859 - acc: 0.7500\n",
      "Epoch 273/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 274/500\n",
      " - 0s - loss: 2.8543 - acc: 0.8214\n",
      "Epoch 275/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 276/500\n",
      " - 0s - loss: 3.4295 - acc: 0.7500\n",
      "Epoch 277/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 278/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 279/500\n",
      " - 0s - loss: 2.6672 - acc: 0.8214\n",
      "Epoch 280/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 281/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 282/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 283/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 284/500\n",
      " - 0s - loss: 3.4163 - acc: 0.7857\n",
      "Epoch 285/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 286/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 287/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 288/500\n",
      " - 0s - loss: 3.1788 - acc: 0.7857\n",
      "Epoch 289/500\n",
      " - 0s - loss: 3.2014 - acc: 0.7500\n",
      "Epoch 290/500\n",
      " - 0s - loss: 3.5345 - acc: 0.7500\n",
      "Epoch 291/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 292/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 293/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 294/500\n",
      " - 0s - loss: 2.8573 - acc: 0.8214\n",
      "Epoch 295/500\n",
      " - 0s - loss: 3.7279 - acc: 0.7500\n",
      "Epoch 296/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 297/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 298/500\n",
      " - 0s - loss: 4.0134 - acc: 0.7500\n",
      "Epoch 299/500\n",
      " - 0s - loss: 2.3060 - acc: 0.8214\n",
      "Epoch 300/500\n",
      " - 0s - loss: 3.6285 - acc: 0.7500\n",
      "Epoch 301/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 302/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 303/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 304/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 305/500\n",
      " - 0s - loss: 4.0134 - acc: 0.7500\n",
      "Epoch 306/500\n",
      " - 0s - loss: 3.5182 - acc: 0.7143\n",
      "Epoch 307/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 308/500\n",
      " - 0s - loss: 3.3378 - acc: 0.7857\n",
      "Epoch 309/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 310/500\n",
      " - 0s - loss: 3.6589 - acc: 0.7500\n",
      "Epoch 311/500\n",
      " - 0s - loss: 3.4440 - acc: 0.7857\n",
      "Epoch 312/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 313/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 314/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 315/500\n",
      " - 0s - loss: 2.9050 - acc: 0.7857\n",
      "Epoch 316/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 317/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 318/500\n",
      " - 0s - loss: 3.4243 - acc: 0.7857\n",
      "Epoch 319/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 320/500\n",
      " - 0s - loss: 3.0394 - acc: 0.7857\n",
      "Epoch 321/500\n",
      " - 0s - loss: 4.2970 - acc: 0.7143\n",
      "Epoch 322/500\n",
      " - 0s - loss: 3.4375 - acc: 0.7857\n",
      "Epoch 323/500\n",
      " - 0s - loss: 3.1158 - acc: 0.7857\n",
      "Epoch 324/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 325/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 326/500\n",
      " - 0s - loss: 2.8904 - acc: 0.8214\n",
      "Epoch 327/500\n",
      " - 0s - loss: 3.2706 - acc: 0.7857\n",
      "Epoch 328/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 329/500\n",
      " - 0s - loss: 3.4163 - acc: 0.7857\n",
      "Epoch 330/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 331/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 332/500\n",
      " - 0s - loss: 3.9921 - acc: 0.7500\n",
      "Epoch 333/500\n",
      " - 0s - loss: 2.6130 - acc: 0.8214\n",
      "Epoch 334/500\n",
      " - 0s - loss: 2.8525 - acc: 0.8214\n",
      "Epoch 335/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 336/500\n",
      " - 0s - loss: 2.6737 - acc: 0.7857\n",
      "Epoch 337/500\n",
      " - 0s - loss: 4.5675 - acc: 0.7143\n",
      "Epoch 338/500\n",
      " - 0s - loss: 3.4379 - acc: 0.7857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339/500\n",
      " - 0s - loss: 2.4402 - acc: 0.8214\n",
      "Epoch 340/500\n",
      " - 0s - loss: 3.4392 - acc: 0.7857\n",
      "Epoch 341/500\n",
      " - 0s - loss: 3.0825 - acc: 0.7857\n",
      "Epoch 342/500\n",
      " - 0s - loss: 3.3246 - acc: 0.7857\n",
      "Epoch 343/500\n",
      " - 0s - loss: 3.4596 - acc: 0.7857\n",
      "Epoch 344/500\n",
      " - 0s - loss: 3.4380 - acc: 0.7857\n",
      "Epoch 345/500\n",
      " - 0s - loss: 3.0632 - acc: 0.7857\n",
      "Epoch 346/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 347/500\n",
      " - 0s - loss: 2.5832 - acc: 0.8214\n",
      "Epoch 348/500\n",
      " - 0s - loss: 3.3369 - acc: 0.7857\n",
      "Epoch 349/500\n",
      " - 0s - loss: 2.0490 - acc: 0.8571\n",
      "Epoch 350/500\n",
      " - 0s - loss: 2.2775 - acc: 0.8571\n",
      "Epoch 351/500\n",
      " - 0s - loss: 3.4225 - acc: 0.7857\n",
      "Epoch 352/500\n",
      " - 0s - loss: 3.3228 - acc: 0.7500\n",
      "Epoch 353/500\n",
      " - 0s - loss: 3.1245 - acc: 0.7857\n",
      "Epoch 354/500\n",
      " - 0s - loss: 3.2068 - acc: 0.7857\n",
      "Epoch 355/500\n",
      " - 0s - loss: 2.8947 - acc: 0.7500\n",
      "Epoch 356/500\n",
      " - 0s - loss: 2.8509 - acc: 0.7857\n",
      "Epoch 357/500\n",
      " - 0s - loss: 3.4354 - acc: 0.7857\n",
      "Epoch 358/500\n",
      " - 0s - loss: 2.8747 - acc: 0.7857\n",
      "Epoch 359/500\n",
      " - 0s - loss: 2.5318 - acc: 0.7500\n",
      "Epoch 360/500\n",
      " - 0s - loss: 3.4821 - acc: 0.7857\n",
      "Epoch 361/500\n",
      " - 0s - loss: 3.1603 - acc: 0.7500\n",
      "Epoch 362/500\n",
      " - 0s - loss: 3.4253 - acc: 0.7857\n",
      "Epoch 363/500\n",
      " - 0s - loss: 3.1137 - acc: 0.7857\n",
      "Epoch 364/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 365/500\n",
      " - 0s - loss: 3.4227 - acc: 0.7857\n",
      "Epoch 366/500\n",
      " - 0s - loss: 2.8968 - acc: 0.7857\n",
      "Epoch 367/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 368/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 369/500\n",
      " - 0s - loss: 3.4380 - acc: 0.7857\n",
      "Epoch 370/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 371/500\n",
      " - 0s - loss: 2.6752 - acc: 0.7857\n",
      "Epoch 372/500\n",
      " - 0s - loss: 4.1386 - acc: 0.7143\n",
      "Epoch 373/500\n",
      " - 0s - loss: 3.0360 - acc: 0.7857\n",
      "Epoch 374/500\n",
      " - 0s - loss: 3.4381 - acc: 0.7857\n",
      "Epoch 375/500\n",
      " - 0s - loss: 2.8469 - acc: 0.8214\n",
      "Epoch 376/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 377/500\n",
      " - 0s - loss: 3.3075 - acc: 0.7857\n",
      "Epoch 378/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 379/500\n",
      " - 0s - loss: 3.3833 - acc: 0.7500\n",
      "Epoch 380/500\n",
      " - 0s - loss: 3.3275 - acc: 0.7857\n",
      "Epoch 381/500\n",
      " - 0s - loss: 4.0491 - acc: 0.7143\n",
      "Epoch 382/500\n",
      " - 0s - loss: 3.0156 - acc: 0.7857\n",
      "Epoch 383/500\n",
      " - 0s - loss: 3.4557 - acc: 0.7857\n",
      "Epoch 384/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 385/500\n",
      " - 0s - loss: 2.9185 - acc: 0.7857\n",
      "Epoch 386/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 387/500\n",
      " - 0s - loss: 2.3833 - acc: 0.7857\n",
      "Epoch 388/500\n",
      " - 0s - loss: 3.4381 - acc: 0.7857\n",
      "Epoch 389/500\n",
      " - 0s - loss: 3.4380 - acc: 0.7857\n",
      "Epoch 390/500\n",
      " - 0s - loss: 3.9919 - acc: 0.7500\n",
      "Epoch 391/500\n",
      " - 0s - loss: 3.4408 - acc: 0.7857\n",
      "Epoch 392/500\n",
      " - 0s - loss: 3.4379 - acc: 0.7857\n",
      "Epoch 393/500\n",
      " - 0s - loss: 3.4318 - acc: 0.7857\n",
      "Epoch 394/500\n",
      " - 0s - loss: 2.9728 - acc: 0.7857\n",
      "Epoch 395/500\n",
      " - 0s - loss: 2.8750 - acc: 0.7857\n",
      "Epoch 396/500\n",
      " - 0s - loss: 3.4380 - acc: 0.7857\n",
      "Epoch 397/500\n",
      " - 0s - loss: 3.5860 - acc: 0.7143\n",
      "Epoch 398/500\n",
      " - 0s - loss: 2.8685 - acc: 0.8214\n",
      "Epoch 399/500\n",
      " - 0s - loss: 3.4379 - acc: 0.7857\n",
      "Epoch 400/500\n",
      " - 0s - loss: 3.4450 - acc: 0.7857\n",
      "Epoch 401/500\n",
      " - 0s - loss: 2.2138 - acc: 0.7857\n",
      "Epoch 402/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 403/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 404/500\n",
      " - 0s - loss: 3.0747 - acc: 0.7857\n",
      "Epoch 405/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 406/500\n",
      " - 0s - loss: 2.6596 - acc: 0.7857\n",
      "Epoch 407/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 408/500\n",
      " - 0s - loss: 2.8686 - acc: 0.8214\n",
      "Epoch 409/500\n",
      " - 0s - loss: 3.4904 - acc: 0.7500\n",
      "Epoch 410/500\n",
      " - 0s - loss: 2.4163 - acc: 0.7857\n",
      "Epoch 411/500\n",
      " - 0s - loss: 3.1632 - acc: 0.7857\n",
      "Epoch 412/500\n",
      " - 0s - loss: 4.0319 - acc: 0.7500\n",
      "Epoch 413/500\n",
      " - 0s - loss: 2.8904 - acc: 0.8214\n",
      "Epoch 414/500\n",
      " - 0s - loss: 3.5198 - acc: 0.7500\n",
      "Epoch 415/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 416/500\n",
      " - 0s - loss: 3.4378 - acc: 0.7857\n",
      "Epoch 417/500\n",
      " - 0s - loss: 2.6578 - acc: 0.8214\n",
      "Epoch 418/500\n",
      " - 0s - loss: 3.4378 - acc: 0.7857\n",
      "Epoch 419/500\n",
      " - 0s - loss: 2.8751 - acc: 0.7857\n",
      "Epoch 420/500\n",
      " - 0s - loss: 2.8967 - acc: 0.7857\n",
      "Epoch 421/500\n",
      " - 0s - loss: 3.4378 - acc: 0.7857\n",
      "Epoch 422/500\n",
      " - 0s - loss: 3.0108 - acc: 0.7857\n",
      "Epoch 423/500\n",
      " - 0s - loss: 2.8761 - acc: 0.7857\n",
      "Epoch 424/500\n",
      " - 0s - loss: 2.9264 - acc: 0.7857\n",
      "Epoch 425/500\n",
      " - 0s - loss: 2.8671 - acc: 0.8214\n",
      "Epoch 426/500\n",
      " - 0s - loss: 2.3919 - acc: 0.7857\n",
      "Epoch 427/500\n",
      " - 0s - loss: 4.0137 - acc: 0.7500\n",
      "Epoch 428/500\n",
      " - 0s - loss: 3.8175 - acc: 0.7500\n",
      "Epoch 429/500\n",
      " - 0s - loss: 2.9394 - acc: 0.7857\n",
      "Epoch 430/500\n",
      " - 0s - loss: 3.4173 - acc: 0.7857\n",
      "Epoch 431/500\n",
      " - 0s - loss: 2.8478 - acc: 0.8214\n",
      "Epoch 432/500\n",
      " - 0s - loss: 3.4162 - acc: 0.7857\n",
      "Epoch 433/500\n",
      " - 0s - loss: 2.8685 - acc: 0.8214\n",
      "Epoch 434/500\n",
      " - 0s - loss: 3.2457 - acc: 0.7500\n",
      "Epoch 435/500\n",
      " - 0s - loss: 3.4195 - acc: 0.7857\n",
      "Epoch 436/500\n",
      " - 0s - loss: 3.4529 - acc: 0.7857\n",
      "Epoch 437/500\n",
      " - 0s - loss: 3.4354 - acc: 0.7857\n",
      "Epoch 438/500\n",
      " - 0s - loss: 2.9639 - acc: 0.7857\n",
      "Epoch 439/500\n",
      " - 0s - loss: 2.8753 - acc: 0.7857\n",
      "Epoch 440/500\n",
      " - 0s - loss: 3.1042 - acc: 0.7857\n",
      "Epoch 441/500\n",
      " - 0s - loss: 3.0297 - acc: 0.7857\n",
      "Epoch 442/500\n",
      " - 0s - loss: 2.8470 - acc: 0.8214\n",
      "Epoch 443/500\n",
      " - 0s - loss: 2.8037 - acc: 0.7857\n",
      "Epoch 444/500\n",
      " - 0s - loss: 3.4602 - acc: 0.7857\n",
      "Epoch 445/500\n",
      " - 0s - loss: 3.4511 - acc: 0.7500\n",
      "Epoch 446/500\n",
      " - 0s - loss: 2.5084 - acc: 0.7857\n",
      "Epoch 447/500\n",
      " - 0s - loss: 2.9699 - acc: 0.7857\n",
      "Epoch 448/500\n",
      " - 0s - loss: 2.8943 - acc: 0.8214\n",
      "Epoch 449/500\n",
      " - 0s - loss: 2.8717 - acc: 0.8214\n",
      "Epoch 450/500\n",
      " - 0s - loss: 3.4381 - acc: 0.7857\n",
      "Epoch 451/500\n",
      " - 0s - loss: 3.0602 - acc: 0.7857\n",
      "Epoch 452/500\n",
      " - 0s - loss: 2.9327 - acc: 0.7857\n",
      "Epoch 453/500\n",
      " - 0s - loss: 3.4176 - acc: 0.7857\n",
      "Epoch 454/500\n",
      " - 0s - loss: 2.8985 - acc: 0.7857\n",
      "Epoch 455/500\n",
      " - 0s - loss: 3.4192 - acc: 0.7857\n",
      "Epoch 456/500\n",
      " - 0s - loss: 2.4156 - acc: 0.7857\n",
      "Epoch 457/500\n",
      " - 0s - loss: 3.0325 - acc: 0.7857\n",
      "Epoch 458/500\n",
      " - 0s - loss: 2.2814 - acc: 0.8571\n",
      "Epoch 459/500\n",
      " - 0s - loss: 3.4305 - acc: 0.7857\n",
      "Epoch 460/500\n",
      " - 0s - loss: 2.3742 - acc: 0.8214\n",
      "Epoch 461/500\n",
      " - 0s - loss: 3.9950 - acc: 0.7500\n",
      "Epoch 462/500\n",
      " - 0s - loss: 2.0423 - acc: 0.8214\n",
      "Epoch 463/500\n",
      " - 0s - loss: 3.4851 - acc: 0.7857\n",
      "Epoch 464/500\n",
      " - 0s - loss: 2.3214 - acc: 0.8214\n",
      "Epoch 465/500\n",
      " - 0s - loss: 2.8853 - acc: 0.7857\n",
      "Epoch 466/500\n",
      " - 0s - loss: 3.4848 - acc: 0.7857\n",
      "Epoch 467/500\n",
      " - 0s - loss: 3.4694 - acc: 0.7857\n",
      "Epoch 468/500\n",
      " - 0s - loss: 2.3590 - acc: 0.8214\n",
      "Epoch 469/500\n",
      " - 0s - loss: 2.5000 - acc: 0.7500\n",
      "Epoch 470/500\n",
      " - 0s - loss: 3.0334 - acc: 0.7857\n",
      "Epoch 471/500\n",
      " - 0s - loss: 2.6725 - acc: 0.7500\n",
      "Epoch 472/500\n",
      " - 0s - loss: 2.9149 - acc: 0.7857\n",
      "Epoch 473/500\n",
      " - 0s - loss: 3.0287 - acc: 0.7500\n",
      "Epoch 474/500\n",
      " - 0s - loss: 2.5068 - acc: 0.7857\n",
      "Epoch 475/500\n",
      " - 0s - loss: 3.4104 - acc: 0.7500\n",
      "Epoch 476/500\n",
      " - 0s - loss: 2.9104 - acc: 0.7857\n",
      "Epoch 477/500\n",
      " - 0s - loss: 1.8097 - acc: 0.8214\n",
      "Epoch 478/500\n",
      " - 0s - loss: 2.4277 - acc: 0.8214\n",
      "Epoch 479/500\n",
      " - 0s - loss: 2.3539 - acc: 0.8214\n",
      "Epoch 480/500\n",
      " - 0s - loss: 2.3550 - acc: 0.7857\n",
      "Epoch 481/500\n",
      " - 0s - loss: 2.4072 - acc: 0.7857\n",
      "Epoch 482/500\n",
      " - 0s - loss: 2.8927 - acc: 0.7857\n",
      "Epoch 483/500\n",
      " - 0s - loss: 3.4168 - acc: 0.7857\n",
      "Epoch 484/500\n",
      " - 0s - loss: 3.0415 - acc: 0.7500\n",
      "Epoch 485/500\n",
      " - 0s - loss: 2.6432 - acc: 0.7500\n",
      "Epoch 486/500\n",
      " - 0s - loss: 2.3547 - acc: 0.8571\n",
      "Epoch 487/500\n",
      " - 0s - loss: 3.4810 - acc: 0.7857\n",
      "Epoch 488/500\n",
      " - 0s - loss: 3.0644 - acc: 0.7857\n",
      "Epoch 489/500\n",
      " - 0s - loss: 1.8480 - acc: 0.7857\n",
      "Epoch 490/500\n",
      " - 0s - loss: 3.4432 - acc: 0.7857\n",
      "Epoch 491/500\n",
      " - 0s - loss: 3.4661 - acc: 0.7857\n",
      "Epoch 492/500\n",
      " - 0s - loss: 3.4378 - acc: 0.7857\n",
      "Epoch 493/500\n",
      " - 0s - loss: 2.5308 - acc: 0.8214\n",
      "Epoch 494/500\n",
      " - 0s - loss: 3.7029 - acc: 0.7500\n",
      "Epoch 495/500\n",
      " - 0s - loss: 1.7695 - acc: 0.7857\n",
      "Epoch 496/500\n",
      " - 0s - loss: 3.4459 - acc: 0.7857\n",
      "Epoch 497/500\n",
      " - 0s - loss: 1.8498 - acc: 0.8214\n",
      "Epoch 498/500\n",
      " - 0s - loss: 3.2598 - acc: 0.7857\n",
      "Epoch 499/500\n",
      " - 0s - loss: 2.9454 - acc: 0.7857\n",
      "Epoch 500/500\n",
      " - 0s - loss: 1.5908 - acc: 0.8214\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "\n",
    "inputfile1 = '../data/train_neural_network_data.xls'\n",
    "inputfile2 = '../data/test_neural_network_data.xls'\n",
    "testoutputfile = '../tmp/test_output_data.xls'\n",
    "\n",
    "data_train = pd.read_excel(inputfile1)\n",
    "data_test = pd.read_excel(inputfile2)\n",
    "\n",
    "x_train = data_train.iloc[:, 5:17].values\n",
    "y_train = data_train.iloc[:, 4].values\n",
    "x_test = data_test.iloc[:, 5:17].values\n",
    "y_test = data_test.iloc[:, 4].values\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(17,activation='relu',input_dim=11))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', class_mode='binary')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=500, batch_size=1,verbose=2) #82.14%\n",
    "\n",
    "model.save_weights('../tmp/net.model')\n",
    "\n",
    "r=pd.DataFrame(model.predict_classes(x_test),columns=[u'预测结果'])\n",
    "pd.concat([data_test.iloc[:,:5],r],axis=1).to_excel(testoutputfile)\n",
    "model.predict(x_test)\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "#https://blog.csdn.net/chadian3912/article/details/81976956\n",
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型评价\n",
    "根据该热水器用户提供的用水日志来判断事件是否为洗浴与多层神经网络模型识别结果的比较。由于我们的实验数据量较小，总共21条检测数据，准确识别了18条。模型对洗浴事件的识别准确率为85%左右。\n",
    "## 实验总结\n",
    "\n",
    "本实验基于实时监控的智能热水器的用户使用数据，重点介绍了数据挖掘中的数据预处理的数据清洗、数据规约、数据变换等方法，以及数据预处理在实际案例中 的应用，并建立了热水器的洗浴事件识别的神经网络模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
